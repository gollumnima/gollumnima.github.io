{"componentChunkName":"component---src-templates-post-template-js","path":"/posts/wecode6_2TIL_crawling","webpackCompilationHash":"de91277daf84bfa90327","result":{"data":{"markdownRemark":{"id":"6e1c48c6-dec0-52e6-ab10-976002bc8248","html":"<p><img src=\"https://images.velog.io/post-images/dooreplay/602d4930-d209-11e9-93d3-efc48314c767/image.png\" alt=\"image.png\"></p>\n<h2 id=\"웹-크롤링이란\"><a href=\"#%EC%9B%B9-%ED%81%AC%EB%A1%A4%EB%A7%81%EC%9D%B4%EB%9E%80\" aria-label=\"웹 크롤링이란 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>웹 크롤링이란?</h2>\n<p>Web scraping. 웹사이트에서 원하는 정보를 추출하는 일!\n데이터를 긁어온다는 의미에서 아이스크림을 긁는게 생각나서 오늘의 썸네일은 아이스크림!</p>\n<p>데이터 분석에 대한 수요가 증가하고 이에 따라 자료를 얻는 원천으로 웹을 자주 드는데, 이 웹을 가져와서 분석을 할 수 있는 자료 형태로 바꾸는게 바로 크롤링!<br/>\nhttp request 통해서 http가 출력해주는 api를 통해 json 데이터를 가져오는 것을 말한다.</p>\n<h2 id=\"크롤링-관련-사이트\"><a href=\"#%ED%81%AC%EB%A1%A4%EB%A7%81-%EA%B4%80%EB%A0%A8-%EC%82%AC%EC%9D%B4%ED%8A%B8\" aria-label=\"크롤링 관련 사이트 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>크롤링 관련 사이트</h2>\n<ul>\n<li>서울시 공공 데이터 포털</li>\n<li>공공 데이터 포털</li>\n<li>일별 박스 오피스 API</li>\n</ul>\n<h2 id=\"크롤링은-책임감있게\"><a href=\"#%ED%81%AC%EB%A1%A4%EB%A7%81%EC%9D%80-%EC%B1%85%EC%9E%84%EA%B0%90%EC%9E%88%EA%B2%8C\" aria-label=\"크롤링은 책임감있게 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>크롤링은 책임감있게..!</h2>\n<p>크롤링은 자유지만, 웹사이트 무단 크롤링은 <em>불법!</em> <br />\n개인 영리적 이익을 취하지 않는 경우나 시스템에 가하지 않으면 크게 문제 되지 않지만 저작권에 대해선 항상 염두해두어야 한다. <br />\n<br />Robots에 disabled 써있으면 크롤링 하지말라는 뜻! 잘 확인하고 항상 조심하자!</p>\n<h2 id=\"how-to\"><a href=\"#how-to\" aria-label=\"how to permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>how to?</h2>\n<ul>\n<li>scrapy : 규모가 클 때 쓰기, python에 있는 크롤링을 위한 라이브러리 <br /></li>\n<li>urllib : fetch하는 느낌으로 쓸 수 있음</li>\n<li>selenium : 기억이 안남… 이름 예쁨 원석 이름 같음ㅋㅋ</li>\n<li>beautiful soup : 파싱된 response를 객체화 시켜주는 툴</li>\n<li>requests - 소셜로그인 기능 구현할 때 백에서 쓰는 라이브러리</li>\n</ul>\n<p><br /> <br />\njs에서는…</p>\n<ul>\n<li>puppeteer</li>\n<li>apify</li>\n<li>cheerio\n같은게 있다고 한다.. 내가 세션때 제대로 받아 적은게 맞는지 모르겠지만 여튼ㅋㅋㅋ</li>\n</ul>\n<h2 id=\"해보자-실습\"><a href=\"#%ED%95%B4%EB%B3%B4%EC%9E%90-%EC%8B%A4%EC%8A%B5\" aria-label=\"해보자 실습 permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>해보자 실습!</h2>\n<ol>\n<li>requests 깔기\n<code class=\"language-text\">pip install requests</code>\n가상환경 구축은 생략~</li>\n<li>bs4 깔기\n<code class=\"language-text\">pip install bs4</code>\n(beautiful spoon 4탄임.)</li>\n</ol>\n<p>일단 이 두개 깔면 크롤링할 준비 완료쓰~</p>\n<ol start=\"3\">\n<li>python 파일 하나 만들기</li>\n</ol>\n<p>request 하면 화면 전체를 다 가져오는 것 -> 터미널에서 확인할 수 있음</p>\n<p>html까지 하면 string만 나와서 복잡쓰\n예쁜스푼을 쓰자! 객체형태로 보여줌</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">import requests\nfrom bs4 import BeautifulSoup\n\nreq = requests.get(&#39;http://www.mnet.com/chart/TOP100/20190826&#39;)\n\n\nhtml = req.text\n\nsoup = BeautifulSoup(html, &#39;html.parser&#39;)\n\nmnet_songs = soup.select(\n    &#39;tr &gt; td.MMLItemTitle &gt; div &gt; div.MMLITitle_Box.info &gt; div.MMLITitleSong_Box &gt; a.MMLI_SongInfo&#39;\n)\n\nfor song in mnet_songs :\n    print(song.text)</code></pre></div>\n<p>for문을 저렇게 쓰는것도 넘 신기하고…\n빽의 세계는 암튼 다 신기함!\n<br />그치만 일단 나는 프론트 할거지롱</p>\n<p><code class=\"language-text\">python crawling.py</code> 입력하면 터미널에 결과 나옴</p>\n<p><img src=\"https://images.velog.io/post-images/dooreplay/2f3ad700-c88d-11e9-bc39-4fa6ed49fec8/image.png\" alt=\"image.png\">\n<br />핵신기함ㅋㅋㅋㅋㅋㅋㅋㅋㅋ 대박…\n근데 프론트랑 다르게 결과물을 웹페이지가 아닌 터미널로 확인해야 한다는 점이 넘 불편쓰..☆</p>\n<p>중간에 내쪽에서 뭐가 안 되가지고 중간 설명은 생략…!\n결과물 공개해본다</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">import requests\nfrom bs4 import BeautifulSoup\nfrom sqlalchemy import *\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import relationship, sessionmaker\nfrom sqlalchemy.sql import *\n\nengine = create_engine(&#39;sqlite:///music.db&#39;)\nBase = declarative_base()\n\nclass Music(Base):\n    __tablename__ = &#39;musics&#39;\n    id = Column(Integer, primary_key=True)\n    rank = Column(String(50))\n    songs = Column(String(50))\n    singer = Column(String(50))\n    album = Column(String(50))\n\nMusic.__table__.create(bind=engine, checkfirst=True)\n\n\nSession = sessionmaker(bind=engine)\nsession = Session()\n\nreq = requests.get(&#39;http://mnet.com/chart/TOP100/20190826&#39;)\n\nhtml = req.text\n\nsoup = BeautifulSoup(html, &#39;html.parser&#39;)\n\nrank = soup.select(\n    &#39;tr &gt; td.MMLItemRank &gt; div &gt; span&#39;\n)\n\nmy_songs = soup.select(\n    &#39;tr &gt; td.MMLItemTitle &gt; div &gt; div.MMLITitle_Box.info &gt; div.MMLITitleSong_Box &gt; a.MMLI_Song&#39;\n)\n\nsinger = soup.select(\n    &#39;tr &gt; td.MMLItemTitle &gt; div &gt; div.MMLITitle_Box.info &gt; div.MMLITitle_Info &gt; a.MMLIInfo_Artist&#39;\n)\n\nalbum = soup.select(\n    &#39;tr &gt; td.MMLItemTitle &gt; div &gt; div.MMLITitle_Box.info &gt; div.MMLITitle_Info &gt; a.MMLIInfo_Album&#39;\n)\n\nmusic_chart = []\n\nfor item in zip(rank, my_songs, singer, album):\n    music_chart.append(\n        {\n            &#39;rank&#39; : item[0].text,\n            &#39;song&#39; : item[1].text,\n            &#39;singer&#39; : item[2].text,\n            &#39;album&#39;  : item[3].text,\n       }\n    )\n\nfor element in music_chart:\n    print(element)\n\nfor element in music_chart:\n    result =  Music(rank=element[&#39;rank&#39;],\n                    songs=element[&#39;song&#39;],\n                    singer=element[&#39;singer&#39;],\n                    album=element[&#39;album&#39;]\n    )\n    session.add(result)\n    session.commit()\n\nrequest = session.query(Music).all()\n\nfor row in request:\n   print(row.rank,row.songs,row.singer,row.album)</code></pre></div>\n<p>기억이 잘 안나지만 중간에 <code class=\"language-text\">pip install sqlalchemy</code> 설치했음\n여튼 중간에 컴터가 멈춰서 강제종료 했던 기억이 있다!</p>\n<p>나의 결과물…</p>\n<p><img src=\"https://images.velog.io/post-images/dooreplay/c56ff520-c892-11e9-ad06-c7058f1fcfa5/image.png\" alt=\"image.png\"></p>\n<p>아까 노래제목까진 잘 나왔었는데…아놔 웬 이상한 문자열들이 뙇..!\n멘토님의 코드를 똑같이 복붙했는데 나만 왜 이런가 했더니만 우분투 문제였다 <br />\n<br />애증 말고 증뿐인 우분투.. 증증증이다 증말 ㅡ,.ㅡ\n우분투 바보멍청이!</p>\n<p>여튼 나도 해봤다, 크롤링!</p>","fields":{"slug":"/posts/wecode6_2TIL_crawling","tagSlugs":["/tag/wecode/","/tag/codingbootcamp/","/tag/crawling/","/tag/backend/","/tag/위코드/"]},"frontmatter":{"date":"2019-09-03T16:16:04.169Z","description":"위코드 31일차. 오랜만에 약간 백 이야기! 언제 한번 해보고 싶었던 크롤링... 위코드에서 세션이 열려서 드디어 나도 한번 해보았다!","tags":["wecode","codingbootcamp","crawling","backend","위코드"],"title":"wecode 6주차_2일 TIL_도전! 크롤링 해보기"}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/posts/wecode6_2TIL_crawling"}}}